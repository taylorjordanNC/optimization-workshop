1. Get the OpenAI API base URL by running these commands:
{{- if .Values.route.enabled }}
  route_hostname=$(kubectl get --namespace {{ .Release.Namespace }} route {{ include "vllm.fullname" . }} -o jsonpath='{.status.ingress[0].host}')
  {{- $proto := ternary "https" "http" .Values.route.tls.enabled }}
  {{- printf "" | nindent 2 }}echo {{ $proto }}://${route_hostname}/v1
{{- else if contains "NodePort" .Values.service.type }}
  export NODE_PORT=$(kubectl get --namespace {{ .Release.Namespace }} -o jsonpath="{.spec.ports[0].nodePort}" services {{ include "vllm.fullname" . }})
  export NODE_IP=$(kubectl get nodes --namespace {{ .Release.Namespace }} -o jsonpath="{.items[0].status.addresses[0].address}")
  echo http://$NODE_IP:$NODE_PORT/v1
{{- else if contains "LoadBalancer" .Values.service.type }}
     NOTE: It may take a few minutes for the LoadBalancer IP to be available.
           You can watch its status by running 'kubectl get --namespace {{ .Release.Namespace }} svc -w {{ include "vllm.fullname" . }}'
  export SERVICE_IP=$(kubectl get svc --namespace {{ .Release.Namespace }} {{ include "vllm.fullname" . }} --template "{{"{{ range (index .status.loadBalancer.ingress 0) }}{{.}}{{ end }}"}}")
  echo http://$SERVICE_IP:{{ .Values.service.port }}/v1
{{- else if contains "ClusterIP" .Values.service.type }}
  echo http://127.0.0.1:8000/v1
  kubectl --namespace {{ .Release.Namespace }} port-forward svc/{{ include "vllm.fullname" . }} 8000:{{ .Values.service.port }}
{{- end }}

{{- range $k, $v := .Values.configuration.env }}
{{- if eq $k "HF_HUB_OFFLINE" }}
Warning: You provided an HF_HUB_OFFLINE environment variable, which is ignored as it's controlled via the .configuration.hfModelDownload.enabled value.
{{- end }}
{{- end }}
